name: ESR Upgrade
on:
  workflow_call:
    inputs:
      db-dump-url:
        required: true
        type: string
      final-migration:
        required: true
        type: number
      final-version:
        required: true
        type: string
      migration-script-path:
        required: true
        type: string
      cleanup-script-path:
        required: true
        type: string
env:
  COMPOSE_PROJECT_NAME: ghactions
  BUILD_IMAGE: mattermost/mattermost-enterprise-edition:${{ inputs.final-version }}
  MYSQL_CONN_ARGS: -h localhost -P 3306 --protocol=tcp -ummuser -pmostest mattermost_test
  DUMP_SERVER_NAME: dump.${{ inputs.final-version }}.server.sql
  DUMP_SCRIPT_NAME: dump.${{ inputs.final-version }}.script.sql
  DIFF_NAME: diff.${{ inputs.final-version }}.sql
jobs:
  esr-upgrade-server:
    runs-on: ubuntu-latest-8-cores
    timeout-minutes: 30
    steps:
      - name: Checkout mattermost-server
        uses: actions/checkout@ac593985615ec2ede58e132d2e21d2b1cbd6127c # v3.3.0
      - name: Run docker compose
        run: |
          cd build
          docker-compose --no-ansi run --rm start_dependencies
          cat ../tests/test-data.ldif | docker-compose --no-ansi exec -T openldap bash -c 'ldapadd -x -D "cn=admin,dc=mm,dc=test,dc=com" -w mostest';
          docker-compose --no-ansi exec -T minio sh -c 'mkdir -p /data/mattermost-test';
          docker-compose --no-ansi ps
      - name: Wait for docker compose
        run: |
          until docker network inspect ghactions_mm-test; do echo "Waiting for Docker Compose Network..."; sleep 1; done;
          docker run --net ghactions_mm-test appropriate/curl:latest sh -c "until curl --max-time 5 --output - http://mysql:3306; do echo waiting for mysql; sleep 5; done;"
          docker run --net ghactions_mm-test appropriate/curl:latest sh -c "until curl --max-time 5 --output - http://elasticsearch:9200; do echo waiting for elasticsearch; sleep 5; done;"
      - name: Initialize the database with the source DB dump
        run: |
          curl ${{ inputs.db-dump-url }} | zcat | docker exec -i ghactions_mysql_1 mysql -AN $MYSQL_CONN_ARGS
      - name: Pull EE image
        run: |
          docker pull $BUILD_IMAGE
      - name: Run migration through server
        run: |
          mkdir -p client/plugins
          cd build
          # Run the server in the background to trigger the migrations
          docker run --name mmserver \
            --net ghactions_mm-test \
            --ulimit nofile=8096:8096 \
            --env-file=dotenv/test.env \
            --env MM_SQLSETTINGS_DRIVERNAME="mysql" \
            --env MM_SQLSETTINGS_DATASOURCE="mmuser:mostest@tcp(mysql:3306)/mattermost_test?charset=utf8mb4,utf8&multiStatements=true" \
            -v ~/work/mattermost-server:/mattermost-server \
            -w /mattermost-server/mattermost-server \
            $BUILD_IMAGE &
          # In parallel, wait for the migrations to finish.
          # To verify this, we check whether the db_migrations table contains the latest migration in this version
          CHECK_LATEST_MIGRATION_CMD="SELECT COUNT(1) FROM db_migrations WHERE Version = ${{ inputs.final-migration }};"
          until [ `docker exec ghactions_mysql_1 mysql -AN $MYSQL_CONN_ARGS -e "$CHECK_LATEST_MIGRATION_CMD"` -eq 1 ]; do\
            echo "Waiting for migrations to finish..."; \
            sleep 1; \
            done;
          # Make sure to stop the server. Also, redirect output to null;
          # otherwise, the name of the container gets written to the console, which is weird
          docker stop mmserver > /dev/null
      - name: Cleanup DB
        run : |
          cd scripts/esrupgrades
          docker exec -i ghactions_mysql_1 mysql -AN $MYSQL_CONN_ARGS < ${{ inputs.cleanup-script-path }}
      - name: Dump upgraded database
        run: |
          # Ignore tables containing meta-information about the migrations (db_{lock,migrations}),
          # since those will not be present in the upgrade from the script.
          # Use --skip-opt to have each INSERT into one line.
          # Use --set-gtid-purged=OFF to suppress GTID-related statements.
          docker exec -i ghactions_mysql_1 mysqldump \
            --ignore-table=mattermost_test.db_lock \
            --ignore-table=mattermost_test.db_migrations \
            --skip-opt --set-gtid-purged=OFF \
            $MYSQL_CONN_ARGS > $DUMP_SERVER_NAME
      - name: Cleanup dump and compress
        run: |
          # We skip the very last line, which simply contains the date of the dump
          head -n -1 ${DUMP_SERVER_NAME} | gzip > ${DUMP_SERVER_NAME}.gz
      - name: Upload dump
        uses: actions/upload-artifact@v3
        with:
          name: upgraded-dump-server
          path: ${{ env.DUMP_SERVER_NAME }}.gz
  esr-upgrade-script:
    runs-on: ubuntu-latest-8-cores
    steps:
      - name: Checkout mattermost-server
        uses: actions/checkout@ac593985615ec2ede58e132d2e21d2b1cbd6127c # v3.3.0
      - name: Run docker compose
        run: |
          cd build
          docker-compose --no-ansi run --rm start_dependencies
          cat ../tests/test-data.ldif | docker-compose --no-ansi exec -T openldap bash -c 'ldapadd -x -D "cn=admin,dc=mm,dc=test,dc=com" -w mostest';
          docker-compose --no-ansi exec -T minio sh -c 'mkdir -p /data/mattermost-test';
          docker-compose --no-ansi ps
      - name: Wait for docker compose
        run: |
          until docker network inspect ghactions_mm-test; do echo "Waiting for Docker Compose Network..."; sleep 1; done;
          docker run --net ghactions_mm-test appropriate/curl:latest sh -c "until curl --max-time 5 --output - http://mysql:3306; do echo waiting for mysql; sleep 5; done;"
          docker run --net ghactions_mm-test appropriate/curl:latest sh -c "until curl --max-time 5 --output - http://elasticsearch:9200; do echo waiting for elasticsearch; sleep 5; done;"
      - name: Initialize the database with the source DB dump
        run: |
          curl ${{ inputs.db-dump-url }} | zcat | docker exec -i ghactions_mysql_1 mysql -AN $MYSQL_CONN_ARGS
      - name: Run migration through script
        run : |
          cd scripts/esrupgrades
          docker exec -i ghactions_mysql_1 mysql -AN $MYSQL_CONN_ARGS < ${{ inputs.migration-script-path }}
      - name: Cleanup DB
        run : |
          cd scripts/esrupgrades
          docker exec -i ghactions_mysql_1 mysql -AN $MYSQL_CONN_ARGS < ${{ inputs.cleanup-script-path }}
      - name: Dump upgraded database
        run: |
          docker exec -i ghactions_mysql_1 mysqldump --skip-opt --set-gtid-purged=OFF $MYSQL_CONN_ARGS > $DUMP_SCRIPT_NAME
      - name: Cleanup dump and compress
        run: |
          # We skip the very last line, which simply contains the date of the dump
          head -n -1 ${DUMP_SCRIPT_NAME} | gzip > ${DUMP_SCRIPT_NAME}.gz
      - name: Upload dump
        uses: actions/upload-artifact@v3
        with:
          name: upgraded-dump-script
          path: ${{ env.DUMP_SCRIPT_NAME }}.gz
  esr-upgrade-diff:
    runs-on: ubuntu-latest-8-cores
    needs:
      - esr-upgrade-server
      - esr-upgrade-script
    steps:
      - name: Retrieve dumps
        uses: actions/download-artifact@v3
      - name: Diff dumps
        run: |
          gzip -d upgraded-dump-server/${DUMP_SERVER_NAME}.gz
          gzip -d upgraded-dump-script/${DUMP_SCRIPT_NAME}.gz
          diff upgraded-dump-server/$DUMP_SERVER_NAME upgraded-dump-script/$DUMP_SCRIPT_NAME > $DIFF_NAME
      - name: Upload diff
        if: failure() # Upload the diff only if the previous step failed; i.e., if the diff is non-empty
        uses: actions/upload-artifact@v3
        with:
          name: dumps-diff
          path: ${{ env.DIFF_NAME }}
